{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages \n",
    "import networkx as nx\n",
    "import json\n",
    "from networkx.readwrite import json_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph for HI with 5 nodes.\n",
      "Loaded graph for IA with 99 nodes.\n",
      "Loaded graph for ID with 44 nodes.\n",
      "Loaded graph for IN with 92 nodes.\n",
      "Loaded graph for KS with 105 nodes.\n",
      "Loaded graph for LA with 64 nodes.\n",
      "Loaded graph for MA with 14 nodes.\n",
      "Loaded graph for MD with 24 nodes.\n",
      "Loaded graph for ME with 16 nodes.\n",
      "Loaded graph for MI with 83 nodes.\n",
      "Loaded graph for MN with 87 nodes.\n",
      "Loaded graph for MS with 82 nodes.\n",
      "Loaded graph for MT with 56 nodes.\n",
      "Loaded graph for ND with 53 nodes.\n",
      "Loaded graph for NE with 93 nodes.\n",
      "Loaded graph for NH with 10 nodes.\n",
      "Loaded graph for NJ with 21 nodes.\n",
      "Loaded graph for NM with 33 nodes.\n",
      "Loaded graph for NY with 62 nodes.\n",
      "Loaded graph for PA with 67 nodes.\n",
      "Loaded graph for RI with 5 nodes.\n",
      "Loaded graph for SC with 46 nodes.\n",
      "Loaded graph for SD with 66 nodes.\n",
      "Loaded graph for TN with 95 nodes.\n",
      "Loaded graph for TX with 254 nodes.\n",
      "Loaded graph for UT with 29 nodes.\n",
      "Loaded graph for VA with 133 nodes.\n",
      "Loaded graph for VT with 14 nodes.\n",
      "Loaded graph for WA with 39 nodes.\n",
      "Loaded graph for WI with 72 nodes.\n",
      "Loaded graph for WV with 55 nodes.\n",
      "Loaded graph for WY with 23 nodes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx.readwrite.json_graph as json_graph\n",
    "\n",
    "# Set the base directory where all the files are stored\n",
    "base_dir = '/Users/brookefeinberg/SamplingBalancedForests/'\n",
    "\n",
    "# List of all 50 US state abbreviations\n",
    "state_abbrs = [\n",
    "    \"hi\", \"ia\", \"id\", \"in\", \"ks\", \"la\", \"ma\", \"md\",\n",
    "    \"me\", \"mi\", \"mn\", \"ms\", \"mt\", \"nd\", \"ne\", \"nh\",\n",
    "    \"nj\", \"nm\", \"ny\", \"pa\", \"ri\", \"sc\",\n",
    "    \"sd\", \"tn\", \"tx\", \"ut\", \"va\", \"vt\", \"wa\", \"wi\", \"wv\", \"wy\"\n",
    "]\n",
    "\n",
    "# Dictionary to store graph data for each state\n",
    "state_graphs = {}\n",
    "\n",
    "# Iterate through each state abbreviation and load the corresponding JSON\n",
    "for abbr in state_abbrs:\n",
    "    file_path = os.path.join(base_dir, f'cnty_{abbr}.json')\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            graph = json_graph.adjacency_graph(data)\n",
    "            state_graphs[abbr] = graph\n",
    "            print(f\"Loaded graph for {abbr.upper()} with {len(graph)} nodes.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for {abbr.upper()}: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {abbr.upper()}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cnty data \n",
    "file_path = '/Users/brookefeinberg/SamplingBalancedForests/cnty_al.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "    cnty = json_graph.adjacency_graph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wilson's Algorithm\n",
    "\n",
    "class WilsonsAlgorithm:\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph  #store networkX graph \n",
    "        self.adj_list = {v: list(graph.neighbors(v)) for v in graph.nodes() if list(graph.neighbors(v))}  #for each graph node return the neighbors and store it as a dictionary where node is the key and each value corresponds to a list of its neighbors \n",
    "        self.InTree = {node: False for node in self.adj_list}  #initalizes dictionary to keep track of whether nodes have been included in the spanning tree -- FALSE as initial value menaing node has yet to be included in the tree \n",
    "        self.Next = {node: None for node in self.adj_list}  #initalizes dictionary to track path each node takes in a random walk \n",
    "    \n",
    "    def random_edge(self, v): #randomly selects an edge for a given node v \n",
    "        return random.choice(self.adj_list[v]) #retrieves the list of neighbors for node v in the adjacency list and randomly picks one -- simulating step ina  random walk \n",
    "\n",
    "    def RandomTreeWithRoot(self, r): #generate random spanning tree with r as the root node \n",
    "        self.InTree = {node: False for node in self.adj_list} #initalize all nodes as not in the spanning tree \n",
    "        self.InTree[r] = True  #mark root node as in the tree \n",
    "        self.Next[r] = -1  #root node has no parent aka no incoming edges \n",
    "\n",
    "        for node in self.adj_list: #loops through each nodein the graph, attempting to find a path to the root using a random walk \n",
    "            path = []  \n",
    "            while not self.InTree[node]: #loop continues as long as node is not already in the spanning tree \n",
    "                path.append(node)  #record each step of the random walk \n",
    "                self.Next[node] = self.random_edge(node) #choose a random neighbor & record it as the next step in the walk (connects node to its next random neighbor in the path)\n",
    "                node = self.Next[node]  #update next node and the new node so the loop continues till we reach a node already in the spanning tree \n",
    "            for vertex in path:  #loop has broken bc we've reached a node already part of the spanning tree \n",
    "                self.InTree[vertex] = True  #adds each vertex to the spanning tree from the root outward \n",
    "\n",
    "    def sample(self, seed=None):\n",
    "        if seed is not None: #can include seed later on for reproducible results \n",
    "            random.seed(seed)\n",
    "        root = random.choice(list(self.adj_list.keys()))  #picks a random node to be a root \n",
    "        self.RandomTreeWithRoot(root) #builds ranodm spannign tree with the ranodm root chosen \n",
    "\n",
    "        spanning_tree = []  #extract edges of spannign tree for plotting \n",
    "        for node in self.adj_list: \n",
    "            if self.Next[node] != -1 and self.Next[node] is not None: #find nodes connected to another node in the tree \n",
    "                spanning_tree.append((node, self.Next[node])) #addes connection or edge as a tuple of two nodes to the spanning tree list \n",
    "        return spanning_tree, root #returns all the edges in the form of (node1, node2) and the root node \n",
    "\n",
    "    def draw_tree(self, spanning_tree, root, node_locations): #plot the spanning tree on the graph\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        nx.draw(self.graph, pos=node_locations, node_size=10, edge_color='lightgray') #draw original graph \n",
    "        nx.draw_networkx_edges(self.graph, pos=node_locations, edgelist=spanning_tree, edge_color='red', width=2) #draw spanning tree \n",
    "        nx.draw_networkx_nodes(self.graph, pos=node_locations, nodelist=[root], node_color='yellow', node_size=50)  #draw root node \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BFS Graph Partitioner \n",
    "class GraphPartitioner:\n",
    "    def __init__(self, graph, k):\n",
    "        self.graph = graph\n",
    "        self.k = k\n",
    "\n",
    "    def create_weighted_partitions_and_draw_spanning_tree(self):\n",
    "        while True:\n",
    "            wilson = WilsonsAlgorithm(self.graph) #generate random spannign tree using wilson's algorithm \n",
    "            spanning_tree, root = wilson.sample() \n",
    "\n",
    "            tree_graph = nx.Graph() \n",
    "            tree_graph.add_edges_from(spanning_tree)  #take edges form spannign tree and add them to the new graph\n",
    "\n",
    "            total_nodes = len(tree_graph) \n",
    "            ideal_size = total_nodes // self.k\n",
    "            extra_nodes = total_nodes % self.k\n",
    "            target_sizes = [ideal_size + 1 if i < extra_nodes else ideal_size for i in range(self.k)] #accomedate odd nodes \n",
    "\n",
    "            partitions = [[] for _ in range(self.k)] # initalize BFS queues \n",
    "            partition_sizes = [0] * self.k\n",
    "            bfs_queues = [deque([root])] + [deque() for _ in range(self.k - 1)] \n",
    "\n",
    "            visited = set([root])\n",
    "            partitions[0].append(root)\n",
    "            partition_sizes[0] += 1\n",
    "\n",
    "            for current_partition in range(self.k):\n",
    "                while partition_sizes[current_partition] < target_sizes[current_partition] and bfs_queues[current_partition]:\n",
    "                    node = bfs_queues[current_partition].popleft()\n",
    "                    for neighbor in tree_graph.neighbors(node):\n",
    "                        if neighbor not in visited:\n",
    "                            partitions[current_partition].append(neighbor)\n",
    "                            partition_sizes[current_partition] += 1\n",
    "                            visited.add(neighbor)\n",
    "                            bfs_queues[current_partition].append(neighbor)\n",
    "                            if partition_sizes[current_partition] >= target_sizes[current_partition]:\n",
    "                                break\n",
    "                            \n",
    "                # check if partition has reached the right size--else continue the loop for a new tree            \n",
    "                if partition_sizes[current_partition] < target_sizes[current_partition]:\n",
    "                    #print(\"Attempt failed, generating a new spanning tree.\")\n",
    "                    return False          #initalizae for statistical inference \n",
    "                    #break  \n",
    "\n",
    "                # initalize next partition with an unvisited node \n",
    "                unvisited_nodes = [n for n in tree_graph.nodes if n not in visited]\n",
    "                if unvisited_nodes and current_partition + 1 < self.k:\n",
    "                    seed_node = unvisited_nodes[0]\n",
    "                    partitions[current_partition + 1].append(seed_node)\n",
    "                    partition_sizes[current_partition + 1] += 1\n",
    "                    visited.add(seed_node)\n",
    "                    bfs_queues[current_partition + 1].append(seed_node)\n",
    "\n",
    "            # check if all partitions are the right size\n",
    "            if all(partition_sizes[i] == target_sizes[i] for i in range(self.k)):\n",
    "                #print(\"Balanced partitions found.\")\n",
    "                return True\n",
    "                #break\n",
    "              \n",
    "        # Step 3: Plotting \n",
    "        node_locations = {v: (float(cnty.nodes()[v][\"INTPTLON20\"]) - 360 if float(cnty.nodes()[v][\"INTPTLON20\"]) > 0 else float(cnty.nodes()[v][\"INTPTLON20\"]),\n",
    "        float(cnty.nodes()[v][\"INTPTLAT20\"]))for v in cnty.nodes()}\n",
    "        pos = node_locations\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        base_colors = ['blue', 'green']\n",
    "        spanning_tree_pos = {node: pos[node] for node in tree_graph.nodes}\n",
    "        for i, partition in enumerate(partitions):\n",
    "            nx.draw_networkx_nodes(tree_graph, spanning_tree_pos, nodelist=partition, node_size=50,\n",
    "                                   node_color=base_colors[i % len(base_colors)], label=f'Partition {i+1}')\n",
    "        nx.draw_networkx_edges(tree_graph, spanning_tree_pos, edge_color='gray', width=2)\n",
    "        plt.legend()\n",
    "        plt.title(\"Spanning Tree with Weighted, Connected, Balanced Partitions\")\n",
    "        plt.show()\n",
    "        return True\n",
    "\n",
    "\n",
    "G = cnty  \n",
    "k = 3 \n",
    "partitioner = GraphPartitioner(G, k)\n",
    "partitioner.create_weighted_partitions_and_draw_spanning_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph for HI with 5 nodes.\n",
      "Loaded graph for ID with 44 nodes.\n",
      "Loaded graph for IN with 92 nodes.\n",
      "Loaded graph for KS with 105 nodes.\n",
      "Loaded graph for LA with 64 nodes.\n",
      "Loaded graph for MA with 14 nodes.\n",
      "Loaded graph for MD with 24 nodes.\n",
      "Loaded graph for ME with 16 nodes.\n",
      "Loaded graph for MI with 83 nodes.\n",
      "Loaded graph for MN with 87 nodes.\n",
      "Loaded graph for MS with 82 nodes.\n",
      "Loaded graph for MT with 56 nodes.\n",
      "Loaded graph for ND with 53 nodes.\n",
      "Loaded graph for NE with 93 nodes.\n",
      "Loaded graph for NH with 10 nodes.\n",
      "Loaded graph for NJ with 21 nodes.\n",
      "Loaded graph for NM with 33 nodes.\n",
      "Loaded graph for NY with 62 nodes.\n",
      "Loaded graph for PA with 67 nodes.\n",
      "Loaded graph for RI with 5 nodes.\n",
      "Loaded graph for SC with 46 nodes.\n",
      "Loaded graph for SD with 66 nodes.\n",
      "Loaded graph for TN with 95 nodes.\n",
      "Loaded graph for UT with 29 nodes.\n",
      "Loaded graph for VT with 14 nodes.\n",
      "Loaded graph for WA with 39 nodes.\n",
      "Loaded graph for WI with 72 nodes.\n",
      "Loaded graph for WV with 55 nodes.\n",
      "Loaded graph for WY with 23 nodes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx.readwrite.json_graph as json_graph\n",
    "\n",
    "# Set the base directory where all the files are stored\n",
    "base_dir = '/Users/brookefeinberg/SamplingBalancedForests/'\n",
    "\n",
    "# List of all 50 US state abbreviations\n",
    "state_abbrs = [\n",
    "    \"hi\", \"id\", \"in\", \"ks\", \"la\", \"ma\", \"md\",\n",
    "    \"me\", \"mi\", \"mn\", \"ms\", \"mt\", \"nd\", \"ne\", \"nh\",\n",
    "    \"nj\", \"nm\", \"ny\", \"pa\", \"ri\", \"sc\",\n",
    "    \"sd\", \"tn\", \"ut\", \"vt\", \"wa\", \"wi\", \"wv\", \"wy\"\n",
    "]\n",
    "\n",
    "# Dictionary to store graph data for each state\n",
    "state_graphs = {}\n",
    "\n",
    "# Iterate through each state abbreviation and load the corresponding JSON\n",
    "for abbr in state_abbrs:\n",
    "    file_path = os.path.join(base_dir, f'cnty_{abbr}.json')\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            graph = json_graph.adjacency_graph(data)\n",
    "            state_graphs[abbr] = graph\n",
    "            print(f\"Loaded graph for {abbr.upper()} with {len(graph)} nodes.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for {abbr.upper()}: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {abbr.upper()}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running simulations for HI\n",
      "HI: Took 178 trials → Success Rate: 100.00%\n",
      "\n",
      "Running simulations for ID\n",
      "ID: Took 232062 trials → Success Rate: 0.08%\n",
      "\n",
      "Running simulations for IN\n",
      "IN: Took 2614864 trials → Success Rate: 0.01%\n",
      "\n",
      "Running simulations for KS\n",
      "KS: Took 2856067 trials → Success Rate: 0.01%\n",
      "\n",
      "Running simulations for LA\n",
      "LA: Took 516187 trials → Success Rate: 0.03%\n",
      "\n",
      "Running simulations for MA\n",
      "MA: Took 5249 trials → Success Rate: 3.39%\n",
      "\n",
      "Running simulations for MD\n",
      "MD: Took 66602 trials → Success Rate: 0.27%\n",
      "\n",
      "Running simulations for ME\n",
      "ME: Took 7564 trials → Success Rate: 2.35%\n",
      "\n",
      "Running simulations for MI\n",
      "MI: Took 2053149 trials → Success Rate: 0.01%\n",
      "\n",
      "Running simulations for MN\n",
      "MN: Took 1903682 trials → Success Rate: 0.01%\n",
      "\n",
      "Running simulations for MS\n",
      "MS: Took 1832824 trials → Success Rate: 0.01%\n",
      "\n",
      "Running simulations for MT\n",
      "MT: Took 461619 trials → Success Rate: 0.04%\n",
      "\n",
      "Running simulations for ND\n",
      "ND: Took 322401 trials → Success Rate: 0.06%\n",
      "\n",
      "Running simulations for NE\n",
      "NE: Took 1866586 trials → Success Rate: 0.01%\n",
      "\n",
      "Running simulations for NH\n",
      "NH: Took 1382 trials → Success Rate: 12.88%\n",
      "\n",
      "Running simulations for NJ\n",
      "NJ: Took 12253 trials → Success Rate: 1.45%\n",
      "\n",
      "Running simulations for NM\n",
      "NM: Took 70856 trials → Success Rate: 0.25%\n",
      "\n",
      "Running simulations for NY\n",
      "NY: Took 259673 trials → Success Rate: 0.07%\n",
      "\n",
      "Running simulations for PA\n",
      "PA: Took 1154299 trials → Success Rate: 0.02%\n",
      "\n",
      "Running simulations for RI\n",
      "RI: Took 178 trials → Success Rate: 100.00%\n",
      "\n",
      "Running simulations for SC\n",
      "SC: Took 320566 trials → Success Rate: 0.06%\n",
      "\n",
      "Running simulations for SD\n",
      "SD: Took 530538 trials → Success Rate: 0.03%\n",
      "\n",
      "Running simulations for TN\n",
      "TN: Took 1699163 trials → Success Rate: 0.01%\n",
      "\n",
      "Running simulations for UT\n",
      "UT: Took 30138 trials → Success Rate: 0.59%\n",
      "\n",
      "Running simulations for VT\n",
      "VT: Took 3582 trials → Success Rate: 4.97%\n",
      "\n",
      "Running simulations for WA\n",
      "WA: Took 105932 trials → Success Rate: 0.17%\n",
      "\n",
      "Running simulations for WI\n",
      "WI: Took 949412 trials → Success Rate: 0.02%\n",
      "\n",
      "Running simulations for WV\n",
      "WV: Took 665576 trials → Success Rate: 0.03%\n",
      "\n",
      "Running simulations for WY\n",
      "WY: Took 24051 trials → Success Rate: 0.74%\n"
     ]
    }
   ],
   "source": [
    "def run_partition_simulationsss(graph, p, k):\n",
    "    successful_splits = 0\n",
    "    trials = 0\n",
    "\n",
    "    while successful_splits < k:\n",
    "        trials += 1\n",
    "        partitioner = GraphPartitioner(graph, p)\n",
    "        \n",
    "        if partitioner.create_weighted_partitions_and_draw_spanning_tree():\n",
    "            successful_splits += 1\n",
    "\n",
    "    success_rate = (k / trials) * 100\n",
    "    return trials, success_rate\n",
    "\n",
    "\n",
    "# Run partition simulations for all 50 states\n",
    "p = 4  # Number of partitions\n",
    "k = 178  # Number of successful splits to target\n",
    "\n",
    "results = {}  # Store results for each state\n",
    "\n",
    "for abbr, graph in state_graphs.items():\n",
    "    print(f\"\\nRunning simulations for {abbr.upper()}\")\n",
    "    try:\n",
    "        trials, success_rate = run_partition_simulationsss(graph, p, k)\n",
    "        results[abbr] = {\n",
    "            \"trials\": trials,\n",
    "            \"success_rate\": success_rate\n",
    "        }\n",
    "        print(f\"{abbr.upper()}: Took {trials} trials → Success Rate: {success_rate:.2f}%\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error running partition simulations for {abbr.upper()}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
