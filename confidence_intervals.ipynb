{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p (mean): 0.5000\n",
      "95% Confidence Interval: (0.9948, 1.0052)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gamma\n",
    "\n",
    "def gbas_algorithm(k):\n",
    "    S = 0  # success counter\n",
    "    R = 0  # accumulated sum of exponential random variables\n",
    "    \n",
    "    while S < k:\n",
    "        X = np.random.binomial(1, 0.5)  # Simulated thinning process\n",
    "        A = np.random.exponential(1)\n",
    "        S += X\n",
    "        R += A\n",
    "    \n",
    "    # Estimate p using the GBAS formula\n",
    "    hat_p = (k - 1) / R\n",
    "    return hat_p, R\n",
    "\n",
    "\n",
    "def gbas_confidence_interval(k, alpha=0.10, trials=1000):\n",
    "    estimates = []\n",
    "    for i in range(trials):\n",
    "        hat_p, i = gbas_algorithm(k)\n",
    "        estimates.append(hat_p)\n",
    "    \n",
    "    # Use the Gamma distribution for CI\n",
    "    scale = 1 / (k - 1)\n",
    "    mean_estimate = np.mean(estimates)\n",
    "    ci_low = gamma.ppf(alpha / 2, a=k, scale=scale)\n",
    "    ci_high = gamma.ppf(1 - alpha / 2, a=k, scale=scale)\n",
    "    \n",
    "    return mean_estimate, ci_low, ci_high\n",
    "\n",
    "\n",
    "# Input Parameters\n",
    "n = 1000  # Total number of trials\n",
    "p_hat = 100 # Observed success rate from experiment\n",
    "k = int(n * p_hat)  # Number of observed successes\n",
    "mean_p, ci_low, ci_high = gbas_confidence_interval(k)\n",
    "\n",
    "print(f\"Estimated p (mean): {mean_p:.4f}\")\n",
    "print(f\"95% Confidence Interval: ({ci_low:.4f}, {ci_high:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p: 0.9984\n",
      "Total R accumulated: 180291.4318\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gbas_algorithm(k):\n",
    "    \"\"\"\n",
    "    GBAS algorithm to estimate p without knowing its value.\n",
    "    \n",
    "    Parameters:\n",
    "        k (int): Number of successes to simulate.\n",
    "        \n",
    "    Returns:\n",
    "        float: Estimated p using GBAS.\n",
    "        float: Total R value accumulated during the process.\n",
    "    \"\"\"\n",
    "    S = 0  # Success counter\n",
    "    R = 0  # Accumulated sum of exponential random variables\n",
    "    \n",
    "    while S < k:\n",
    "        # Generate Bernoulli random variable X indirectly via self-thinning\n",
    "        A = np.random.exponential(1)  # Exponential random variable\n",
    "        retain_probability = np.random.uniform(0, 1)  # Simulates thinning\n",
    "        X = 1 if retain_probability < 1 else 0  # Equivalent to Bernoulli(p)\n",
    "        \n",
    "        # Update counters\n",
    "        S += X\n",
    "        R += A\n",
    "    \n",
    "    # Estimate p using the GBAS formula\n",
    "    hat_p = (k - 1) / R\n",
    "    return hat_p, R\n",
    "\n",
    "# Example usage\n",
    "##k = 180000  # Number of successes based on observed data (e.g., 0.18 * 1,000,000)\n",
    "estimated_p, total_R = gbas_algorithm(k)\n",
    "#print(f\"Estimated p: {estimated_p:.4f}\")\n",
    "#print(f\"Total R accumulated: {total_R:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     63\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m180000\u001b[39m  \u001b[38;5;66;03m# Total successes based on observed data (e.g., 0.18 * 1,000,000)\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m mean_p, ci_low, ci_high \u001b[38;5;241m=\u001b[39m \u001b[43mgbas_confidence_interval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimated p (mean): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_p\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m95% Confidence Interval: (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mci_low\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mci_high\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m, in \u001b[0;36mgbas_confidence_interval\u001b[0;34m(k, alpha, trials)\u001b[0m\n\u001b[1;32m     47\u001b[0m estimates \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trials):\n\u001b[0;32m---> 49\u001b[0m     hat_p, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgbas_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     estimates\u001b[38;5;241m.\u001b[39mappend(hat_p)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Calculate mean of estimates\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mgbas_algorithm\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m     16\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Accumulated sum of exponential random variables\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m S \u001b[38;5;241m<\u001b[39m k:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Generate a Bernoulli random variable X indirectly via self-thinning\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexponential\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exponential random variable\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     retain_probability \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# gonna always almost be less than one \u001b[39;00m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;66;03m#never gonna get you something less tha one\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gamma\n",
    "\n",
    "def gbas_algorithm(k):\n",
    "    \"\"\"\n",
    "    GBAS algorithm to estimate p without knowing its value.\n",
    "    \n",
    "    Parameters:\n",
    "        k (int): Number of successes to simulate.\n",
    "        \n",
    "    Returns:\n",
    "        float: Estimated p using GBAS.\n",
    "        float: Total R value accumulated during the process.\n",
    "    \"\"\"\n",
    "    S = 0  # Success counter\n",
    "    R = 0  # Accumulated sum of exponential random variables\n",
    "    \n",
    "    while S < k:\n",
    "        # Generate a Bernoulli random variable X indirectly via self-thinning\n",
    "        A = np.random.exponential(1)  # Exponential random variable\n",
    "        retain_probability = np.random.uniform(0, 1)  # gonna always almost be less than one \n",
    "\n",
    "            #never gonna get you something less tha one\n",
    "\n",
    "        X = 1 if retain_probability < 1 else 0  # Equivalent to Bernoulli(p)\n",
    "        \n",
    "        # Update counters\n",
    "        S += X\n",
    "        R += A\n",
    "    \n",
    "    # Estimate p using the GBAS formula\n",
    "    hat_p = (k - 1) / R\n",
    "    return hat_p, R\n",
    "\n",
    "def gbas_confidence_interval(k, alpha=0.05, trials=100000):\n",
    "    \"\"\"\n",
    "    Runs the GBAS algorithm and computes confidence intervals for p.\n",
    "    \n",
    "    Parameters:\n",
    "        k (int): Number of successes to simulate.\n",
    "        alpha (float): Significance level for CI (default is 0.05 for 95% CI).\n",
    "        trials (int): Number of GBAS runs for accuracy.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Mean estimated p, lower bound, upper bound.\n",
    "    \"\"\"\n",
    "    estimates = []\n",
    "    for _ in range(trials):\n",
    "        hat_p, _ = gbas_algorithm(k)\n",
    "        estimates.append(hat_p)\n",
    "    \n",
    "    # Calculate mean of estimates\n",
    "    mean_p = np.mean(estimates)\n",
    "    \n",
    "    # Use Gamma distribution to calculate confidence bounds\n",
    "    scale = 1 / (k - 1)  # Scale parameter for Gamma distribution\n",
    "    ci_low = gamma.ppf(alpha / 2, a=k, scale=scale)\n",
    "    ci_high = gamma.ppf(1 - alpha / 2, a=k, scale=scale)\n",
    "    \n",
    "    return mean_p, ci_low, ci_high\n",
    "\n",
    "# Example usage\n",
    "k = 180000  # Total successes based on observed data (e.g., 0.18 * 1,000,000)\n",
    "mean_p, ci_low, ci_high = gbas_confidence_interval(k, trials=1000000)\n",
    "\n",
    "print(f\"Estimated p (mean): {mean_p:.4f}\")\n",
    "print(f\"95% Confidence Interval: ({ci_low:.4f}, {ci_high:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
